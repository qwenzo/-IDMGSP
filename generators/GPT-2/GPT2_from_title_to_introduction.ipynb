{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMHUlogNdmHp"
      },
      "source": [
        "# Fine-tuning GPT-2\n",
        "## Write an introduction given the title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lejOYc_JnkUI"
      },
      "source": [
        "##Â Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpfBZRmX29LZ",
        "outputId": "4c14b5bc-5e36-48c5-b900-2de776b472d9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "\n",
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments,AutoModelWithLMHead\n",
        "import csv\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbgK1bf429Lb",
        "outputId": "b99713d1-1d89-4841-c2f2-9a2943f039f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# instantiate the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2',sep_token = '<|sep|>',truncation=True, max_length=600000)\n",
        "tokenizer.model_max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy44zQ8Q29Lc",
        "outputId": "11772628-0228-495a-8d4d-373c3c0c6c17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def load_dataset(train_path,test_path,tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "     \n",
        "    val_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)   \n",
        "    \n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset,val_dataset,data_collator\n",
        "\n",
        "# data loading (data already preprocessed by adding special tokens)\n",
        "train_dataset,val_dataset,data_collator = load_dataset('train_gpt2_introduction.txt','val_gpt2_introduction.txt', tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbjpq4DK29Ld",
        "outputId": "29e50650-853f-4957-ab47-b0548b8410aa",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/modeling_auto.py:1248: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Embedding(50258, 768)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# istantiate the model (gpt-2 small with 12-layer, 768-hidden, 12-heads, 117M parameters)\n",
        "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gfZalqbh29Le"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./model_parameters\",  # define the output directory\n",
        "    overwrite_output_dir=True,        # True if we want to overwrite the content of the output directory\n",
        "    num_train_epochs=6,               # number of training epochs\n",
        "    per_device_train_batch_size=16,   # batch size for training\n",
        "    per_device_eval_batch_size=16,    # batch size for evaluation\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=400,\n",
        "    eval_steps=200,                   # number of update steps between two evaluations\n",
        "    save_steps=600,                   # number of update steps before saving the update model \n",
        "    warmup_steps=200,                 # number of warmup steps for learning rate scheduler\n",
        "    )\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ELmA2n929Lf",
        "outputId": "5001f17e-e38c-4783-fa1e-dd4c3fb099e0",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# move the computation on the gpu, if available \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "tkjNXrti29Lf",
        "outputId": "6bc70324-a183-4ee0-8bab-e6586c4bf3d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 3670\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1380\n",
            "  Number of trainable parameters = 124440576\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1380' max='1380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1380/1380 13:05, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>9.527300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.519100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.356500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./model_parameters/checkpoint-600\n",
            "Configuration saved in ./model_parameters/checkpoint-600/config.json\n",
            "Configuration saved in ./model_parameters/checkpoint-600/generation_config.json\n",
            "Model weights saved in ./model_parameters/checkpoint-600/pytorch_model.bin\n",
            "Saving model checkpoint to ./model_parameters/checkpoint-1200\n",
            "Configuration saved in ./model_parameters/checkpoint-1200/config.json\n",
            "Configuration saved in ./model_parameters/checkpoint-1200/generation_config.json\n",
            "Model weights saved in ./model_parameters/checkpoint-1200/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1380, training_loss=5.184949968863225, metrics={'train_runtime': 788.203, 'train_samples_per_second': 27.937, 'train_steps_per_second': 1.751, 'total_flos': 1438412636160000.0, 'train_loss': 5.184949968863225, 'epoch': 6.0})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpVG5pOV29Lg",
        "outputId": "1e40be4a-1008-4780-a64a-7327dcbcb137"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in ./model/config.json\n",
            "Configuration saved in ./model/generation_config.json\n",
            "Model weights saved in ./model/pytorch_model.bin\n",
            "tokenizer config file saved in ./model/tokenizer_config.json\n",
            "Special tokens file saved in ./model/special_tokens_map.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./model/tokenizer_config.json',\n",
              " './model/special_tokens_map.json',\n",
              " './model/vocab.json',\n",
              " './model/merges.txt',\n",
              " './model/added_tokens.json',\n",
              " './model/tokenizer.json')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save\n",
        "model_path = \"./model\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM948T3JicuK"
      },
      "source": [
        "## Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LkQ_409oxX6",
        "outputId": "d1940110-40e3-48df-e325-b1cf779aa7be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff4-cdrH1S0d",
        "outputId": "12544e02-6a5a-4ba5-b13a-d14ff61dabf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/modeling_auto.py:1248: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n",
            "loading configuration file ./model/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"./model\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50258\n",
            "}\n",
            "\n",
            "loading weights file ./model/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "loading configuration file ./model/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load\n",
        "model_path = \"./model\"\n",
        "model = AutoModelWithLMHead.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "569jWgQHoMQ0",
        "outputId": "62bbaaa3-34a3-4791-f2cd-9b32c1664ee8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file ./model/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"./model\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50258\n",
            "}\n",
            "\n",
            "loading configuration file ./model/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"./model\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50258\n",
            "}\n",
            "\n",
            "loading weights file ./model/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "loading configuration file ./model/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/merges.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 50,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "# Generate ans store new data\n",
        "import pandas as pd\n",
        "generator = pipeline('text-generation', model=model_path, tokenizer='gpt2', device=0)\n",
        "\n",
        "def generate_introduction(text):\n",
        "    # generate the content\n",
        "    t = generator(text, do_sample=True, max_length=512, top_k=50, top_p=0.50, num_return_sequences=1)[0]['generated_text']\n",
        "    # remove the input string \n",
        "    t = t[len(text):]\n",
        "    # search the first upper case letter and delete what was generate before it\n",
        "    m = re.search(\"[A-Z]\", t)\n",
        "    if m is not None:\n",
        "      m = m.start()\n",
        "      t = t[m:]\n",
        "    # remove \\n and add . if necessary\n",
        "    t = t.replace('\\n', ' ').rsplit('. ', 1)[0] + '.'\n",
        "    # remove additional parts generated\n",
        "    if t.find('<|sep|>'):\n",
        "      x = t.find('<|sep|>')\n",
        "      t = t[:x].rsplit('. ', 1)[0] + '.'\n",
        "    return t\n",
        "\n",
        "titles = pd.read_csv('./gpt2.csv')['title']\n",
        "\n",
        "# create the output file\n",
        "with open(\"./gpt2_from_title_to_introduction.csv\",'w') as csvfile:\n",
        "  # write the header\n",
        "  writer = csv.DictWriter(csvfile, fieldnames=['title', 'introduction'])\n",
        "  writer.writeheader()\n",
        "  # generate the content for each title and append it to the output file\n",
        "  for elem in titles:\n",
        "    writer.writerow({\"title\": elem,'introduction': generate_introduction(str(elem + '<|sep|>'))})"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
